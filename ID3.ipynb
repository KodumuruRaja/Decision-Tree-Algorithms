{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ID3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoaeLtxAlqwRvfDi191j8D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KodumuruRaja/Decision-Tree-Algorithms/blob/main/ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o22E0stDOELL"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "df_tennis = pd.read_csv('/content/tennis.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJGHS1KGOVzB"
      },
      "source": [
        "from collections import Counter\r\n",
        "def entropy_list(a_list):\r\n",
        "    cnt = Counter(x for x in a_list)\r\n",
        "    num_instance = len(a_list)*1.0\r\n",
        "    probs = [x/num_instance for x in cnt.values()]\r\n",
        "    return entropy(probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShCxsKUCOZq9"
      },
      "source": [
        "import math\r\n",
        "def entropy(probs):\r\n",
        "    return sum([-prob*math.log(prob,2) for prob in probs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F4NcbiQOc4C"
      },
      "source": [
        "def info_gain(df,split,target,trace=0):\r\n",
        "    df_split = df.groupby(split)\r\n",
        "    nobs = len(df.index)*1.0\r\n",
        "    df_agg_ent = df_split.agg({ target:[entropy_list, lambda x: len(x)/nobs] })\r\n",
        "    #print(df_agg_ent)\r\n",
        "    df_agg_ent.columns = ['Entropy','PropObserved']\r\n",
        "    new_entropy = sum( df_agg_ent['Entropy'] * df_agg_ent[\"PropObserved\"])\r\n",
        "    old_entropy = entropy_list(df[target])\r\n",
        "    return old_entropy - new_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGKCBP7qOijT"
      },
      "source": [
        "def id3(df,target,attribute_name,default_class = None):\r\n",
        "    cnt = Counter(x for x in df[target])\r\n",
        "    if len(cnt)==1:\r\n",
        "        return next(iter(cnt))\r\n",
        "    elif df.empty or (not attribute_name):\r\n",
        "        return default_class\r\n",
        "    else:\r\n",
        "        default_class = max(cnt.keys())\r\n",
        "        gains = [info_gain(df,attr,target) for attr in attribute_name]\r\n",
        "        index_max = gains.index(max(gains))\r\n",
        "        best_attr = attribute_name[index_max]\r\n",
        "        tree = { best_attr:{ } }\r\n",
        "        remaining_attr = [x for x in attribute_name if x!=best_attr]\r\n",
        "        for attr_val, data_subset in df.groupby(best_attr):\r\n",
        "            subtree = id3(data_subset,target,remaining_attr,default_class)\r\n",
        "            tree[best_attr][attr_val] = subtree\r\n",
        "        return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Sb_8J_OmMt"
      },
      "source": [
        "def classify(instance,tree,default = None):\r\n",
        "    attribute = next(iter(tree))\r\n",
        "    if instance[attribute] in tree[attribute].keys():\r\n",
        "        result = tree[attribute][instance[attribute]]\r\n",
        "        if isinstance(result,dict):\r\n",
        "            return classify(instance,result)\r\n",
        "        else:\r\n",
        "            return result\r\n",
        "    else:\r\n",
        "        return default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1rbHGuqOpNo",
        "outputId": "e785aa8b-08f5-4c0b-e258-e9b3b7760b3a"
      },
      "source": [
        "attribute_names = list(df_tennis.columns)\r\n",
        "attribute_names.remove('PlayTennis') #Remove the class attribute\r\n",
        "tree = id3(df_tennis,'PlayTennis',attribute_names)\r\n",
        "print(\"\\n\\nThe Resultant Decision Tree is :\\n\")\r\n",
        "print(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The Resultant Decision Tree is :\n",
            "\n",
            "{'outlook': {'overcast': 'yes', 'rainy': {'windy': {False: 'yes', True: 'no'}}, 'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQhF2OsiOros",
        "outputId": "0f5d4fe8-6e99-45e8-ca63-30bb60cc3ce5"
      },
      "source": [
        "training_data = df_tennis.iloc[1:-4] # all but last thousand instances\r\n",
        "test_data = df_tennis.iloc[-4:] # just the last thousand\r\n",
        "train_tree = id3(training_data, 'PlayTennis', attribute_names)\r\n",
        "print(\"\\n\\nThe Resultant Decision train_tree is :\\n\")\r\n",
        "print(train_tree)\r\n",
        "test_data['predicted2'] = test_data.apply(classify,axis=1,args=(train_tree,'Yes') )\r\n",
        "print ('\\n\\n Training the model for a few samples, and again predicting \\'Playtennis\\' for remaining attribute')\r\n",
        "print('The Accuracy for new trained data is : ' + str( sum(test_data['PlayTennis']==test_data['predicted2'] ) / (1.0*len(test_data.index)) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The Resultant Decision train_tree is :\n",
            "\n",
            "{'outlook': {'overcast': 'yes', 'rainy': {'windy': {False: 'yes', True: 'no'}}, 'sunny': {'temp': {'cool': 'yes', 'hot': 'no', 'mild': 'no'}}}}\n",
            "\n",
            "\n",
            " Training the model for a few samples, and again predicting 'Playtennis' for remaining attribute\n",
            "The Accuracy for new trained data is : 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO92vdJGOvKz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}