{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHAID.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSKxNLDKixfDvgDHMaNlYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KodumuruRaja/Decision-Tree-Algorithms/blob/main/CHAID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "KLH96nhidVGF",
        "outputId": "52217c5f-c7a7-46b8-9e98-512f19cc80b6"
      },
      "source": [
        "from pprint import pprint\r\n",
        "from scipy.stats import chi2, chi2_contingency\r\n",
        "from sys import argv\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "file_name = argv[1]\r\n",
        "\r\n",
        "# alpha values for chi square pruning\r\n",
        "if len(argv) > 2:\r\n",
        "    alpha = float(argv[2])\r\n",
        "else:\r\n",
        "    alpha = 0.05  # 5%\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def partition(a):\r\n",
        "    \"\"\"takes values of an attribute as parameter and splits it based on values\r\n",
        "    params:\r\n",
        "        a (list):\r\n",
        "        list of values of attribute\r\n",
        "    return:\r\n",
        "         (dict):\r\n",
        "         dictionary where keys are various values of attribute and value is array of position where the values occurs\r\n",
        "    \"\"\"\r\n",
        "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}\r\n",
        "\r\n",
        "\r\n",
        "def entropy(s):\r\n",
        "    \"\"\"takes values of an attribute as parameter and returns entropy\r\n",
        "    params:\r\n",
        "        s (list):\r\n",
        "        list of values of attribute\r\n",
        "    return:\r\n",
        "         res (float):\r\n",
        "         Entropy value of the attribute\r\n",
        "    \"\"\"\r\n",
        "    res = 0\r\n",
        "    val, counts = np.unique(s, return_counts=True)\r\n",
        "    freqs = counts.astype('float')/len(s)\r\n",
        "    for p in freqs:\r\n",
        "        if p != 0.0:\r\n",
        "            res -= p * np.log2(p)\r\n",
        "    return res\r\n",
        "\r\n",
        "\r\n",
        "def information_gain(y, x):\r\n",
        "    \"\"\"takes values of an attribute as parameter and returns entropy\r\n",
        "    params:\r\n",
        "        y (list):\r\n",
        "        list of values of class\r\n",
        "        x (list):\r\n",
        "        list of values of attribute\r\n",
        "    return:\r\n",
        "         res (float):\r\n",
        "         Information gain of the attribute\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    res = entropy(y)\r\n",
        "\r\n",
        "    # We partition x, according to attribute values x_i\r\n",
        "    val, counts = np.unique(x, return_counts=True)\r\n",
        "    freqs = counts.astype('float')/len(x)\r\n",
        "\r\n",
        "    # We calculate a weighted average of the entropy\r\n",
        "    for p, v in zip(freqs, val):\r\n",
        "        res -= p * entropy(y[x == v])\r\n",
        "\r\n",
        "    return res\r\n",
        "\r\n",
        "\r\n",
        "def is_pure(s):\r\n",
        "    \"\"\"takes values of class as parameter and returns if all have same value\r\n",
        "    params:\r\n",
        "        s (list):\r\n",
        "        list of values of class\r\n",
        "    return:\r\n",
        "         (boolean):\r\n",
        "         True if pure else false\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    return len(set(s)) == 1\r\n",
        "\r\n",
        "\r\n",
        "def recursive_split(x, y, attr_name):\r\n",
        "    \"\"\"takes examples and values of class as parameter and returns best split of the data\r\n",
        "    params:\r\n",
        "        x (list of list):\r\n",
        "        list of examples having various attributes\r\n",
        "        y (list)\r\n",
        "        list of class values of the examples\r\n",
        "        attr_name (list of string)\r\n",
        "        list of names of the attributes\r\n",
        "    return:\r\n",
        "         (dictionary):\r\n",
        "         key is the best split with max information gain and values is either a class or a dictionary (decision tree)\r\n",
        "    \"\"\"\r\n",
        "    # If there could be no split, just return the original set\r\n",
        "    if is_pure(y) or len(y) == 0:\r\n",
        "        return str(y[0])\r\n",
        "\r\n",
        "    # We get attribute that gives the highest mutual information\r\n",
        "    gain = np.array([information_gain(y, x_attr) for x_attr in x.T])\r\n",
        "    selected_attr = np.argmax(gain)\r\n",
        "\r\n",
        "    # If there's no gain at all, nothing has to be done, just return the original set\r\n",
        "    if np.all(gain < 1e-6):\r\n",
        "        return y\r\n",
        "\r\n",
        "    # We split using the selected attribute\r\n",
        "    sets = partition(x[:, selected_attr])\r\n",
        "\r\n",
        "    res = {}\r\n",
        "    for k, v in sets.items():\r\n",
        "        # create subsets of data based on the split\r\n",
        "        y_subset = y.take(v, axis=0)\r\n",
        "        x_subset = x.take(v, axis=0)\r\n",
        "        x_subset = np.delete(x_subset, selected_attr, 1)\r\n",
        "        attr_name_subset = attr_name[:selected_attr] + attr_name[selected_attr+1:]\r\n",
        "        #recurse on subset of data left\r\n",
        "        res[attr_name[selected_attr] + \" = \" + k ] = recursive_split(x_subset, y_subset, attr_name_subset)\r\n",
        "\r\n",
        "    return res\r\n",
        "\r\n",
        "\r\n",
        "def pruneLeaves(obj):\r\n",
        "    \"\"\"takes decision tree as parameter and returns a pruned tree based on chi square\r\n",
        "    params:\r\n",
        "        obj (dict):\r\n",
        "        obj is a decision tree encoded in the form of decision tree\r\n",
        "    return:\r\n",
        "         obj (dict):\r\n",
        "         obj is decision tree with pruned leaves\r\n",
        "    \"\"\"\r\n",
        "    isLeaf = True\r\n",
        "    parent = None\r\n",
        "    for key in obj:\r\n",
        "        if isinstance(obj[key], dict):\r\n",
        "            isLeaf = False\r\n",
        "            parent = key\r\n",
        "            break\r\n",
        "    if isLeaf and obj.keys()[0].split(' ')[0] not in satisfied_attributes:\r\n",
        "        global pruned\r\n",
        "        pruned = True\r\n",
        "        return 'pruned'\r\n",
        "    if not isLeaf:\r\n",
        "        if pruneLeaves(obj[parent]):\r\n",
        "            obj[parent] = None\r\n",
        "    return obj\r\n",
        "\r\n",
        "\r\n",
        "#read examples from the csv file\r\n",
        "data = np.loadtxt(open('/content/restaurant.csv', \"rb\"), delimiter=\",\", dtype='string', converters = {3: lambda s: s.strip()})\r\n",
        "#get first name for the attribute name\r\n",
        "attr_name = data.take(0,0)[:-1].tolist()\r\n",
        "#get last column for class attribute value\r\n",
        "y = data[...,-1][1:]\r\n",
        "#get rest of the data for the examples\r\n",
        "X = data[...,:-1]\r\n",
        "X = np.delete(X,0,0)\r\n",
        "\r\n",
        "#call recursive_split to train the decision tree\r\n",
        "tree = recursive_split(X, y, attr_name)\r\n",
        "\r\n",
        "satisfied_attributes = []\r\n",
        "for i in range(10):\r\n",
        "    contengency = pd.crosstab(X.T[i], y)\r\n",
        "    c, p, dof, expected = chi2_contingency(contengency)\r\n",
        "    if c > chi2.isf(q=alpha, df=dof):\r\n",
        "        satisfied_attributes.append(attr_name[i])\r\n",
        "\r\n",
        "print ('\\nDecision tree before pruning-\\n')\r\n",
        "pprint(tree)\r\n",
        "\r\n",
        "print ('\\nDecision tree after pruning-\\n')\r\n",
        "pruned = True\r\n",
        "while pruned:\r\n",
        "    #keep pruning till leaf nodes can be pruned or till whole tree has been pruned\r\n",
        "    pruned = False\r\n",
        "    tree = pruneLeaves(tree)\r\n",
        "    if tree == 'pruned':\r\n",
        "        break\r\n",
        "pprint(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-493aae49c607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# alpha values for chi square pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m  \u001b[0;31m# 5%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/root/.local/share/jupyter/runtime/kernel-268bc620-07e5-4b3b-8273-6541874fc2d4.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCGF01xEdwZz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}